{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afff2eca",
   "metadata": {},
   "source": [
    "# Converting .abf to NWB\n",
    "- see `clampfit_abf_standardization_nwb.pptx`\n",
    "- see Sharepoint: `Documents/data/data_standardization/pclamp_clampfit_icephys`\n",
    "- see `ephys_nwb_params.xlsx`: this is maintained by experimenter\n",
    "- **BE SURE TO SET**\n",
    "    - **EXCEL FILE NAME** (`ephys_nwb_params.xlsx` in this example)\n",
    "    - **ABF DIRECTORY** (`abf_data` in this example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cfa57d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pacody/Documents/code/icephys_abf2nwb/env/lib/python3.13/site-packages/pynwb/file.py:158: UserWarning: Date is missing timezone information. Updating to local timezone.\n",
      "  args_to_set['date_of_birth'] = _add_missing_timezone(date_of_birth)\n",
      "/Users/pacody/Documents/code/icephys_abf2nwb/env/lib/python3.13/site-packages/pynwb/file.py:486: UserWarning: Date is missing timezone information. Updating to local timezone.\n",
      "  args_to_set['session_start_time'] = _add_missing_timezone(session_start_time)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Finished NWB conversion for experiment 2025053001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pacody/Documents/code/icephys_abf2nwb/env/lib/python3.13/site-packages/pynwb/file.py:158: UserWarning: Date is missing timezone information. Updating to local timezone.\n",
      "  args_to_set['date_of_birth'] = _add_missing_timezone(date_of_birth)\n",
      "/Users/pacody/Documents/code/icephys_abf2nwb/env/lib/python3.13/site-packages/pynwb/file.py:486: UserWarning: Date is missing timezone information. Updating to local timezone.\n",
      "  args_to_set['session_start_time'] = _add_missing_timezone(session_start_time)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Finished NWB conversion for experiment 2025053101\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from neuroconv.datainterfaces import AbfInterface\n",
    "\n",
    "# Path to Excel and ABF files\n",
    "excel_path = Path(\"./ephys_nwb_params.xlsx\")\n",
    "ECEPHY_DATA_PATH = Path(\"./abf_data\")\n",
    "output_folder = Path(\"./nwb_files\")\n",
    "output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load Excel file\n",
    "df = pd.read_excel(excel_path)\n",
    "df = df.iloc[1:]  # Drop the first row after the header\n",
    "\n",
    "# Clean data: remove completely empty rows and rows with missing critical data\n",
    "df = df.dropna(how=\"all\")  # Remove completely empty rows\n",
    "df = df.dropna(subset=[\"EXPERIMENT ID\", \".abf file\"], how=\"any\")  # Must have these\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Helper function to safely get values (returns empty string for NaN)\n",
    "def safe_get(value, default=\"\"):\n",
    "    return value if pd.notna(value) else default\n",
    "\n",
    "# Helper function to ensure .abf extension\n",
    "def ensure_abf_extension(filename):\n",
    "    \"\"\"Append .abf extension if not already present\"\"\"\n",
    "    if pd.isna(filename):\n",
    "        return filename\n",
    "    filename = str(filename).strip()\n",
    "    if not filename.lower().endswith('.abf'):\n",
    "        filename += '.abf'\n",
    "    return filename\n",
    "\n",
    "# Apply .abf extension fix to the column\n",
    "df[\".abf file\"] = df[\".abf file\"].apply(ensure_abf_extension)\n",
    "\n",
    "# Group by EXPERIMENT ID\n",
    "grouped = df.groupby(\"EXPERIMENT ID\")\n",
    "\n",
    "for experiment_id, group in grouped:\n",
    "    try:\n",
    "        first_row = group.iloc[0]\n",
    "\n",
    "        # Construct icephys_metadata with safe value extraction\n",
    "        icephys_metadata = {\n",
    "            \"cell_id\": safe_get(first_row[\"cell_id\"]),\n",
    "            \"slice_id\": safe_get(first_row[\"slice_id\"]),\n",
    "            \"targeted_layer\": safe_get(first_row[\"targeted_layer\"]),\n",
    "            \"inferred_layer\": safe_get(first_row.get(\"inferred_layer\", \"\")),\n",
    "            \"recording_sessions\": [\n",
    "                {\n",
    "                    \"abf_file_name\": safe_get(row[\".abf file\"]),\n",
    "                    \"stimulus_type\": safe_get(row[\"stimulus_type\"]),\n",
    "                    \"icephys_experiment_type\": safe_get(row[\"icephys_experiment_type\"])\n",
    "                }\n",
    "                for _, row in group.iterrows()\n",
    "                if pd.notna(row[\".abf file\"])  # Extra safety check\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        # Verify ABF files exist\n",
    "        abf_file_paths = []\n",
    "        for _, row in group.iterrows():\n",
    "            if pd.notna(row[\".abf file\"]):\n",
    "                file_path = ECEPHY_DATA_PATH / row[\".abf file\"]\n",
    "                if not file_path.exists():\n",
    "                    print(f\"Warning: ABF file not found: {file_path}\")\n",
    "                    continue\n",
    "                abf_file_paths.append(file_path)\n",
    "\n",
    "        if not abf_file_paths:\n",
    "            print(f\"Skipping experiment {experiment_id}: no valid ABF files found\")\n",
    "            continue\n",
    "\n",
    "        # Instantiate data interface\n",
    "        interface = AbfInterface(\n",
    "            file_paths=abf_file_paths,\n",
    "            icephys_metadata=icephys_metadata\n",
    "        )\n",
    "\n",
    "        # Retrieve and update metadata\n",
    "        metadata = interface.get_metadata()\n",
    "        metadata['NWBFile'].update(\n",
    "            identifier=str(experiment_id),\n",
    "            session_description=safe_get(first_row[\"session_description\"]),\n",
    "            lab=\"my lab name\",\n",
    "            institution=\"My University\",\n",
    "            experimenter=[\"John Doe\", \"Jane Doe\"]\n",
    "        )\n",
    "        metadata[\"Subject\"] = {\n",
    "            \"subject_id\": safe_get(first_row[\"subject_id\"]),\n",
    "            \"species\": safe_get(first_row[\"species\"]),\n",
    "            \"genotype\": safe_get(first_row[\"genotype\"]),\n",
    "            \"sex\": safe_get(first_row[\"sex\"]),\n",
    "            \"date_of_birth\": str(safe_get(first_row[\"date_of_birth\"]))\n",
    "        }\n",
    "\n",
    "        # Run conversion\n",
    "        nwb_output_path = output_folder / f\"{experiment_id}.nwb\"\n",
    "        interface.run_conversion(nwbfile_path=nwb_output_path, metadata=metadata)\n",
    "\n",
    "        print(f\"✓ Finished NWB conversion for experiment {experiment_id}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error processing experiment {experiment_id}: {e}\")\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
